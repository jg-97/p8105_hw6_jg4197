---
title: "p8105_hw6_jg4197"
author: "Jin Ge"
date: "11/14/2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE,
                      fig.height = 8,
                      fig.width = 6)

library(tidyverse)
library(modelr)
library(leaps)

theme_set(theme_bw())

set.seed(1)
```

## tidiness and construct a chosen model

```{r problem 1}
## clean and tidy the data
child_weight <- read_csv("./data_for_hw6/birthweight.csv") %>% 
  janitor::clean_names() %>% 
  drop_na() %>% 
  mutate(babysex = factor(babysex, labels = c("male", "female")),
         frace = factor(frace, levels = c(1, 2, 3, 4, 8, 9),
                        labels = c("white", "black", "asian", "puerto", "other", "unknown")),
         malform = factor(malform, levels = c(0, 1),
                          labels = c("absent", "present")),
         mrace = factor(mrace, levels = c(1, 2, 3, 4, 8),
                        labels = c("white", "black", "asian", "puerto", "other")))
child_weight
  
## propose self-regression model for birthweight
# using rules to select the best model

best <- function(model, ...) 
{
  subsets <- regsubsets(formula(model), model.frame(model), ...)
  subsets <- with(summary(subsets),
                  cbind(p = as.numeric(rownames(which)), which, rss, rsq, adjr2, cp, bic))
  
  return(subsets)
}

all_model <- lm(bwt ~ ., data = child_weight)
best(all_model, nbest = 1)

# we can get the best model with nine parameters by choosing lowest AIC, BIC, rse, highest adjr2

self_model <- child_weight %>% lm(bwt ~ babysex + bhead + blength + delwt + frace + gaweeks + mrace + ppbmi + smoken, data = .)

## reason: lowest AIC, BIC, rse mean the low SSE meaning the variance is low. Highest adjr2 means good proportion of variance of y can be explained by x

# add residuals and predicted values
child_self <- child_weight %>% 
  add_predictions(self_model) %>% 
  add_residuals(self_model)

# show plot b/w prediction and residuals
child_self %>% 
  ggplot(aes(x = pred, y = resid)) + geom_point(alpha = .8, color = "purple") +
  geom_hline(yintercept = 0, color = "red", size = .7) + 
  labs(title = "Residuals vs fitted value plot",
       X = "Predicted fitted value", 
       y = "Residual value")
# except a few cases departing the line y=0, all cases can be seen as the symmetric to y=0. The variance keeps in balance. However, when the fitted value becomes smaller, the residual tend to be increasing.
```


## constrcut two compared models and do comparisons

```{r}

# Do comparisons
cv_df <- crossv_mc(child_weight, 100) %>% 
  mutate(train = map(train, as_tibble),
         test = map(test, as_tibble))


cv_df <- cv_df %>% 
  mutate(self_model = map(train, ~lm(bwt ~ babysex + bhead + blength + delwt + frace + gaweeks + mrace + ppbmi + smoken, data = .x)), 
         comp1_model = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
         comp2_model = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead * blength + bhead * babysex + blength * babysex + bhead * blength * babysex, data = .x)))%>% 
  mutate(rmse_self = map2_dbl(self_model, test, ~rmse(model = .x, data = .y)),
         rmse_comp1 = map2_dbl(comp1_model, test, ~rmse(model = .x, data = .y)),
         rmse_comp2 = map2_dbl(comp2_model, test, ~rmse(model = .x, data = .y)))

# visualization
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_"
  ) %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin(aes(fill = model), alpha = .7) +
  scale_x_discrete(labels = c("self_best_model", "length + gestation", "head + length + sex")) +
  labs(title = "Comparisons on RMSE between three models",
       x = "Type of model",
       y = "RMSE") +
  theme(legend.position = "none")
# the self_model across the model selection has the lowest rmse, meaning the model has the greatest predictive ability since the test data gives a good result.


```

According to the violin plot, we can see the best among three is the _bwt ~ babysex + bhead + blength + delwt + frace + gaweeks + mrace + ppbmi + smoken_ model by selection.


## distribution of two estimates

```{r problem 2}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())


## Do bootstrap and show distribution
## r square
r_square <- weather_df %>%  
  bootstrap(n = 5000) %>% 
  mutate(
    slr_model = map(strap, ~lm(tmax ~ tmin, data = .x)),
    for_r = map(slr_model, broom::glance)
  ) %>% 
  select(-slr_model, everything()) %>% 
  unnest(for_r) %>% 
  select(id = .id, r.squared) 

r_square %>% 
  ggplot(aes(x =r.squared)) +
  geom_density(aes(fill = "pink"), size = 1.1) + 
  geom_vline(aes(xintercept = mean(r.squared)), color = "blue", linetype = "dashed", size = 1) +
  labs(title = "Distribution of r square in 5000 sampling",
       x = "r square",
       y = "Density") +
  theme(legend.position = "none")
## left-skewed

## calculate the CI of r square
quantile(r_square$r.squared, probs = c(0.025, 0.975))


## beta_hat
beta_hat <- weather_df %>%  
  bootstrap(n = 5000) %>% 
  mutate(
    slr_model = map(strap, ~lm(tmax ~ tmin, data = .x)),
    for_betahat = map(slr_model, broom::tidy),
    for_betahat = map(for_betahat, as_tibble)
  ) %>% 
  select(-slr_model, everything()) %>% 
  unnest(for_betahat) %>% 
  select(.id, term, estimate) %>% 
  pivot_wider(
  names_from = "term",
  values_from = "estimate"
) %>% 
  mutate(log_betahat = log(`(Intercept)` * tmin))

beta_hat %>% 
  ggplot(aes(x = log_betahat)) +
  geom_density(aes(fill = "yellow"), size = 1.1) +
  geom_vline(aes(xintercept = mean(log_betahat)),
            color = "blue", linetype = "dashed", size = 1) +
  labs(title = "Distribution of ln(beta0_hat*beta1_hat) in 5000 sampling",
       x = "ln(beta0_hat*beta1_hat)",
       y = "Density") +
  theme(legend.position = "none")
## normal distribution with a slight left-skewed

## calculate the CI of log(beta0*beta1)
quantile(beta_hat$log_betahat, c(0.025, 0.975))

```



